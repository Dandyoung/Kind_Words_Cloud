{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa.display\n",
    "from td_utils import *\n",
    "%matplotlib inline\n",
    "\n",
    "audio_dir = os.path.join('.','data','train_audios')\n",
    "wav_file = 'mix_0.wav'\n",
    "fullname = os.path.join(audio_dir, wav_file)\n",
    "\n",
    "x = graph_spectrogram(fullname)\n",
    "_, data = get_wav_info(fullname)\n",
    "print(\"Time steps in audio recording before spectrogram\", data.shape)\n",
    "print(\"Time steps in input after spectrogram\", x.shape)\n",
    "\n",
    "librosa.display.specshow(x, sr=44100, x_axis='time', y_axis='mel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_freq = 128 # 스펙토그램 높이"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader\n",
    "\n",
    "with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join('.','data', 'XY_train')\n",
    "x_s = []\n",
    "y_s = []\n",
    "for file in os.listdir(data_dir):\n",
    "    if file.startswith('x_'):\n",
    "        x_s.append(os.path.join(data_dir,file))\n",
    "    elif file.startswith('y_'):\n",
    "        y_s.append(os.path.join(data_dir,file))\n",
    "    x_s = sorted(x_s)\n",
    "    y_s = sorted(y_s)\n",
    "df = pd.DataFrame({'x':x_s, 'y':y_s})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.8\n",
    "idxs = list(range(len(df)))\n",
    "np.random.shuffle(idxs)\n",
    "train_idx = idxs[:int(len(df)*train_ratio)]\n",
    "valid_idx = idxs[int(len(df)*train_ratio):]\n",
    "\n",
    "train_df = df.loc[train_idx]\n",
    "valid_df = df.loc[valid_idx]\n",
    "\n",
    "print(train_df.shape, valid_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join('.','data', 'XY_test')\n",
    "x_s = []\n",
    "y_s = []\n",
    "for file in os.listdir(data_dir):\n",
    "    if file.startswith('x_'):\n",
    "        x_s.append(os.path.join(data_dir,file))\n",
    "    elif file.startswith('y_'):\n",
    "        y_s.append(os.path.join(data_dir,file))\n",
    "    x_s = sorted(x_s)\n",
    "    y_s = sorted(y_s)\n",
    "test_df = pd.DataFrame({'x':x_s, 'y':y_s})\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, df, batch_size, shuffle = True):\n",
    "        self.X = list(df.x)\n",
    "        self.y = list(df.y)\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.X))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.X) / self.batch_size))\n",
    "    \n",
    "    def __data_generation(self, X_list, y_list):\n",
    "        X = []\n",
    "        y = []\n",
    "        for i, (img, label) in enumerate(zip(X_list, y_list)):\n",
    "            X.append(np.load(img))\n",
    "            y.append(np.load(label))\n",
    "        \n",
    "        X = np.stack(X, axis=0)\n",
    "        y = np.stack(y, axis=0)\n",
    "\n",
    "        return X, y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "        X_list = [self.X[k] for k in indexes]\n",
    "        y_list = [self.y[k] for k in indexes]\n",
    "        X, y = self.__data_generation(X_list, y_list)\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = DataGenerator(train_df, 5)\n",
    "valid_generator = DataGenerator(valid_df, 5)\n",
    "test_generator = DataGenerator(test_df, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Input, Masking, TimeDistributed, LSTM, Conv1D\n",
    "from keras.layers import GRU, Bidirectional, BatchNormalization, Reshape\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_shape):\n",
    "    \n",
    "    X_input = Input(shape = input_shape)\n",
    "    X = Conv1D(196, kernel_size=15, strides=4)(X_input)         # CONV1D\n",
    "    X = BatchNormalization()(X)                                 # Batch normalization\n",
    "    X = Activation('relu')(X)                                   # ReLu activation\n",
    "    X = Dropout(0.8)(X)                                         # dropout (use 0.8)\n",
    "\n",
    "    X = GRU(units = 128, return_sequences = True)(X)            # GRU (use 128 units and return the sequences)\n",
    "    X = Dropout(0.8)(X)                                         # dropout (use 0.8)\n",
    "    X = BatchNormalization()(X)                                 # Batch normalization\n",
    "\n",
    "    X = GRU(units = 128, return_sequences = True)(X)            # GRU (use 128 units and return the sequences)\n",
    "    X = Dropout(0.8)(X)                                         # dropout (use 0.8)\n",
    "    X = BatchNormalization()(X)                                 # Batch normalization\n",
    "    X = Dropout(0.8)(X)                                         # dropout (use 0.8)\n",
    "\n",
    "    X = TimeDistributed(Dense(1, activation = \"sigmoid\"))(X)    # time distributed  (sigmoid)\n",
    "\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "    return model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model(input_shape = (None, n_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(generator=train_generator,\n",
    "                    validation_data=valid_generator,\n",
    "                    epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocessing(outputs, th):\n",
    "    for output in outputs:\n",
    "        output[output<th] = 0\n",
    "        output[output>=th] = 1\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for batch in test_generator:\n",
    "    x, y = batch\n",
    "    output = model.predict(x)\n",
    "    output = postprocessing(output,0.6)\n",
    "    for i in range(len(y)):\n",
    "        plt.plot(y[i], label='true')\n",
    "        plt.plot(output[i], label='predict')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "rSupZ",
   "launcher_item_id": "cvGhe"
  },
  "kernelspec": {
   "display_name": "pytube",
   "language": "python",
   "name": "pytube"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
